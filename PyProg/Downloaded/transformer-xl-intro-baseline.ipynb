{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9eda96ef-e581-4a39-91c1-d7d89afff649",
    "_uuid": "a3992e6a-6e6e-42e8-bab0-18d9b703f739"
   },
   "source": [
    "A lot of people (i.e kkiller, KeepLearning etc.) have wanted this kernel so here it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0ee6a233-c1f6-4864-bb38-fe0a70982f83",
    "_uuid": "149b1713-3a00-4934-ad49-d47bb9f811e5"
   },
   "source": [
    "Most ideas are taken from the NVIDIA repo (https://github.com/NVIDIA/DeepLearningExamples/blob/master/PyTorch/LanguageModeling/Transformer-XL/pytorch/mem_transformer.py). Credit to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0150d290-2e40-409b-809f-799184c15025",
    "_uuid": "b4e63220-eef2-4c42-9c1b-d680a4c1314d"
   },
   "source": [
    " # Have to give credit to Nvidia and their wonderful GitHub repo.\n",
    " \n",
    " This is a hybridized Transformer-XL which also uses:\n",
    " * CBR Blocks\n",
    " * LSTM-base FFNs\n",
    " * Adaptive Embeddings\n",
    "\n",
    " \n",
    " This has adapted their work into PyTorch. I prefer TF, but PyTorch has the benefit of Open.Ai and their huge ecosystem (Pyro.ai etc).\n",
    " The TFXL was previously written in TF2.1, but I converted it into PyTorch. Why?\n",
    " \n",
    " ### The main reason?\n",
    " \n",
    " **MEGATRON-LM**\n",
    " \n",
    " The monstrous state-of-the-art transformer is the main reason why I am working with PyTorch. I myself only used the TFXL until now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b03df1ea-516e-4dc2-b4af-55b3dd822235",
    "_uuid": "6e697198-dc56-414a-8d05-72588c2e5cfe"
   },
   "source": [
    "My CSV files are in [this dataset](https://www.kaggle.com/nxrprime/preprocessing-for-m5) as well as the official M5 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "08babad2-8fbf-43a3-a907-812d77ba7a68",
    "_uuid": "d07b8f13-3eef-46ba-861a-79caa8c222a1"
   },
   "source": [
    "Unfortunately, the Kaggle kernels environment has very less memory. I cannot run the full NN on Kaggle kernels, so  it has been quicksaved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0c559358-5844-452f-b6c3-85ccd045411d",
    "_uuid": "8afcfa7d-04fd-415e-a378-72f3fb282265"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3f826b81-3f72-43a9-b13b-89b0067a35b7",
    "_uuid": "ba45d46b-79fc-48fb-bd8f-8afa5ddaf683"
   },
   "source": [
    "Just importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "6b3a1074-6f51-44f7-a2d9-4d501e417319",
    "_kg_hide-input": true,
    "_uuid": "1204be0d-b7f5-4ad2-852e-25b1c8b07311"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import gc; import os\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d7f9f98e-7bc5-420e-9da2-7df873b2dec1",
    "_kg_hide-input": true,
    "_uuid": "da6e96d0-9ff1-4d72-b828-4d4d891a7261"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.nn.utils.rnn import pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "156d7bd5-90b0-4ee7-89b0-b5f2bda9bdb8",
    "_uuid": "2e7fcd03-ddd3-454a-845a-55029864c963"
   },
   "outputs": [],
   "source": [
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)]))\n",
    "    return torch.index_select(a, dim, order_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3bb31be0-d47a-400b-8748-5381aeb2dd92",
    "_uuid": "9d8ae679-1e75-485f-ae8f-966d14da3bea"
   },
   "source": [
    "## Definition of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "454203c2-99f7-45b2-bac1-417448bb771b",
    "_uuid": "91a6d01d-b642-4b35-bd55-eb3573ec2b6b"
   },
   "source": [
    "### Megatron-LM GPT2 Layer (for later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d982367c-9d94-4042-8b39-fab9e6aafc02",
    "_uuid": "59ab4a5d-1dd4-4962-97f8-462d31663474"
   },
   "source": [
    "This is a huge and state of the art Attention module. We will be using many besides this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "416b44d8-9744-4174-9872-b090a7a7867d",
    "_uuid": "0cb8d123-6aeb-4340-8641-1b3e9f0e6894"
   },
   "source": [
    "### Feed-forwards\n",
    "\n",
    "We will implement these in our decoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "2b7d435a-4775-4437-bd1c-197d22370eb8",
    "_uuid": "ef8fc917-6b9b-42e8-9e98-bdfe917f4507"
   },
   "outputs": [],
   "source": [
    "class RelMultiHeadAttn(nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_head, dropout, dropatt=0,\n",
    "                 tgt_len=None, ext_len=None, mem_len=None, pre_lnorm=False):\n",
    "        super(RelMultiHeadAttn, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_head = d_head\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.qkv_net = nn.Linear(d_model, 3 * n_head * d_head, bias=False)\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.dropatt = nn.Dropout(dropatt)\n",
    "        self.o_net = nn.Linear(n_head * d_head, d_model, bias=False)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.scale = 1 / (d_head ** 0.5)\n",
    "\n",
    "        self.pre_lnorm = pre_lnorm\n",
    "\n",
    "    def _parallelogram_mask(self, h, w, left=False):\n",
    "        mask = torch.ones((h, w)).byte()\n",
    "        m = min(h, w)\n",
    "        mask[:m,:m] = torch.triu(mask[:m,:m])\n",
    "        mask[-m:,-m:] = torch.tril(mask[-m:,-m:])\n",
    "\n",
    "        if left:\n",
    "            return mask\n",
    "        else:\n",
    "            return mask.flip(0)\n",
    "\n",
    "    def _shift(self, x, qlen, klen, mask, left=False):\n",
    "        if qlen > 1:\n",
    "            zero_pad = torch.zeros((x.size(0), qlen-1, x.size(2), x.size(3)),\n",
    "                                    device=x.device, dtype=x.dtype)\n",
    "        else:\n",
    "            zero_pad = torch.zeros(0, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        if left:\n",
    "            mask = mask.flip(1)\n",
    "            x_padded = torch.cat([zero_pad, x], dim=1).expand(qlen, -1, -1, -1)\n",
    "        else:\n",
    "            x_padded = torch.cat([x, zero_pad], dim=1).expand(qlen, -1, -1, -1)\n",
    "\n",
    "        x = x_padded.masked_select(mask[:,:,None,None]) \\\n",
    "                    .view(qlen, klen, x.size(2), x.size(3))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _rel_shift(self, x, zero_triu=False):\n",
    "        zero_pad = torch.zeros((x.size(0), 1, *x.size()[2:]),\n",
    "                               device=x.device, dtype=x.dtype)\n",
    "        x_padded = torch.cat([zero_pad, x], dim=1)\n",
    "\n",
    "        x_padded = x_padded.view(x.size(1) + 1, x.size(0), *x.size()[2:])\n",
    "\n",
    "        x = x_padded[1:].view_as(x)\n",
    "\n",
    "        if zero_triu:\n",
    "            ones = torch.ones((x.size(0), x.size(1)))\n",
    "            x = x * torch.tril(ones, x.size(1) - x.size(0))[:,:,None,None]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, w, r, attn_mask=None, mems=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class RelPartialLearnableMultiHeadAttn(RelMultiHeadAttn):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(RelPartialLearnableMultiHeadAttn, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.r_net = nn.Linear(self.d_model, self.n_head * self.d_head, bias=False)\n",
    "\n",
    "    def forward(self, w, r, r_w_bias, r_r_bias, attn_mask=None, mems=None):\n",
    "        qlen, rlen, bsz = w.size(0), r.size(0), w.size(1)\n",
    "\n",
    "        if mems is not None:\n",
    "            cat = torch.cat([mems, w], 0)\n",
    "            if self.pre_lnorm:\n",
    "                w_heads = self.qkv_net(self.layer_norm(cat))\n",
    "            else:\n",
    "                w_heads = self.qkv_net(cat)\n",
    "            r_head_k = self.r_net(r)\n",
    "\n",
    "            w_head_q, w_head_k, w_head_v = torch.chunk(w_heads, 3, dim=-1)\n",
    "            w_head_q = w_head_q[-qlen:]\n",
    "        else:\n",
    "            if self.pre_lnorm:\n",
    "                w_heads = self.qkv_net(self.layer_norm(w))\n",
    "            else:\n",
    "                w_heads = self.qkv_net(w)\n",
    "            r_head_k = self.r_net(r)\n",
    "\n",
    "            w_head_q, w_head_k, w_head_v = torch.chunk(w_heads, 3, dim=-1)\n",
    "\n",
    "        klen = w_head_k.size(0)\n",
    "\n",
    "        w_head_q = w_head_q.view(qlen, bsz, self.n_head, self.d_head)           # qlen x bsz x n_head x d_head\n",
    "        w_head_k = w_head_k.view(klen, bsz, self.n_head, self.d_head)           # qlen x bsz x n_head x d_head\n",
    "        w_head_v = w_head_v.view(klen, bsz, self.n_head, self.d_head)           # qlen x bsz x n_head x d_head\n",
    "\n",
    "        r_head_k = r_head_k.view(rlen, self.n_head, self.d_head)                # qlen x n_head x d_head\n",
    "\n",
    "        #### compute attention score\n",
    "        rw_head_q = w_head_q + r_w_bias                                         # qlen x bsz x n_head x d_head\n",
    "        AC = torch.einsum('ibnd,jbnd->ijbn', (rw_head_q, w_head_k))             # qlen x klen x bsz x n_head\n",
    "\n",
    "        rr_head_q = w_head_q + r_r_bias\n",
    "        BD = torch.einsum('ibnd,jnd->ijbn', (rr_head_q, r_head_k))              # qlen x klen x bsz x n_head\n",
    "        BD = self._rel_shift(BD)\n",
    "\n",
    "        # [qlen x klen x bsz x n_head]\n",
    "        attn_score = AC + BD\n",
    "        attn_score.mul_(self.scale)\n",
    "\n",
    "        #### compute attention probability\n",
    "        if attn_mask is not None and attn_mask.any().item():\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_score = attn_score.float().masked_fill(\n",
    "                    attn_mask[None,:,:,None], -float('inf')).type_as(attn_score)\n",
    "            elif attn_mask.dim() == 3:\n",
    "                attn_score = attn_score.float().masked_fill(\n",
    "                    attn_mask[:,:,:,None], -float('inf')).type_as(attn_score)\n",
    "\n",
    "        # [qlen x klen x bsz x n_head]\n",
    "        attn_prob = F.softmax(attn_score, dim=1)\n",
    "        attn_prob = self.dropatt(attn_prob)\n",
    "\n",
    "        #### compute attention vector\n",
    "        attn_vec = torch.einsum('ijbn,jbnd->ibnd', (attn_prob, w_head_v))\n",
    "\n",
    "        # [qlen x bsz x n_head x d_head]\n",
    "        attn_vec = attn_vec.contiguous().view(\n",
    "            attn_vec.size(0), attn_vec.size(1), self.n_head * self.d_head)\n",
    "\n",
    "        ##### linear projection\n",
    "        attn_out = self.o_net(attn_vec)\n",
    "        attn_out = self.drop(attn_out)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            ##### residual connection\n",
    "            output = w + attn_out\n",
    "        else:\n",
    "            ##### residual connection + layer normalization\n",
    "            output = self.layer_norm(w + attn_out)\n",
    "\n",
    "        return output\n",
    "\n",
    "class RelLearnableMultiHeadAttn(RelMultiHeadAttn):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(RelLearnableMultiHeadAttn, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, w, r_emb, r_w_bias, r_bias, attn_mask=None, mems=None):\n",
    "        # r_emb: [klen, n_head, d_head], used for term B\n",
    "        # r_w_bias: [n_head, d_head], used for term C\n",
    "        # r_bias: [klen, n_head], used for term D\n",
    "\n",
    "        qlen, bsz = w.size(0), w.size(1)\n",
    "\n",
    "        if mems is not None:\n",
    "            cat = torch.cat([mems, w], 0)\n",
    "            if self.pre_lnorm:\n",
    "                w_heads = self.qkv_net(self.layer_norm(cat))\n",
    "            else:\n",
    "                w_heads = self.qkv_net(cat)\n",
    "            w_head_q, w_head_k, w_head_v = torch.chunk(w_heads, 3, dim=-1)\n",
    "\n",
    "            w_head_q = w_head_q[-qlen:]\n",
    "        else:\n",
    "            if self.pre_lnorm:\n",
    "                w_heads = self.qkv_net(self.layer_norm(w))\n",
    "            else:\n",
    "                w_heads = self.qkv_net(w)\n",
    "            w_head_q, w_head_k, w_head_v = torch.chunk(w_heads, 3, dim=-1)\n",
    "\n",
    "        klen = w_head_k.size(0)\n",
    "\n",
    "        w_head_q = w_head_q.view(qlen, bsz, self.n_head, self.d_head)\n",
    "        w_head_k = w_head_k.view(klen, bsz, self.n_head, self.d_head)\n",
    "        w_head_v = w_head_v.view(klen, bsz, self.n_head, self.d_head)\n",
    "\n",
    "        if klen > r_emb.size(0):\n",
    "            r_emb_pad = r_emb[0:1].expand(klen-r_emb.size(0), -1, -1)\n",
    "            r_emb = torch.cat([r_emb_pad, r_emb], 0)\n",
    "            r_bias_pad = r_bias[0:1].expand(klen-r_bias.size(0), -1)\n",
    "            r_bias = torch.cat([r_bias_pad, r_bias], 0)\n",
    "        else:\n",
    "            r_emb = r_emb[-klen:]\n",
    "            r_bias = r_bias[-klen:]\n",
    "\n",
    "        #### compute attention score\n",
    "        rw_head_q = w_head_q + r_w_bias[None]                                   # qlen x bsz x n_head x d_head\n",
    "\n",
    "        AC = torch.einsum('ibnd,jbnd->ijbn', (rw_head_q, w_head_k))             # qlen x klen x bsz x n_head\n",
    "        B_ = torch.einsum('ibnd,jnd->ijbn', (w_head_q, r_emb))                  # qlen x klen x bsz x n_head\n",
    "        D_ = r_bias[None, :, None]                                              # 1    x klen x 1   x n_head\n",
    "        BD = self._rel_shift(B_ + D_)\n",
    "\n",
    "        # [qlen x klen x bsz x n_head]\n",
    "        attn_score = AC + BD\n",
    "        attn_score.mul_(self.scale)\n",
    "\n",
    "        #### compute attention probability\n",
    "        if attn_mask is not None and attn_mask.any().item():\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_score.masked_fill_(attn_mask[None,:,:,None], -float('inf'))\n",
    "            elif attn_mask.dim() == 3:\n",
    "                attn_score.masked_fill_(attn_mask[:,:,:,None], -float('inf'))\n",
    "\n",
    "        # [qlen x klen x bsz x n_head]\n",
    "        attn_prob = F.softmax(attn_score, dim=1)\n",
    "        attn_prob = self.dropatt(attn_prob)\n",
    "\n",
    "        #### compute attention vector\n",
    "        attn_vec = torch.einsum('ijbn,jbnd->ibnd', (attn_prob, w_head_v))\n",
    "\n",
    "        # [qlen x bsz x n_head x d_head]\n",
    "        attn_vec = attn_vec.contiguous().view(\n",
    "            attn_vec.size(0), attn_vec.size(1), self.n_head * self.d_head)\n",
    "\n",
    "        ##### linear projection\n",
    "        attn_out = self.o_net(attn_vec)\n",
    "        attn_out = self.drop(attn_out)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            ##### residual connection\n",
    "            output = w + attn_out\n",
    "        else:\n",
    "            ##### residual connection + layer normalization\n",
    "            output = self.layer_norm(w + attn_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "575ee6dd-b489-4332-a792-18683ae412c7",
    "_kg_hide-input": true,
    "_uuid": "231e11b5-c35d-463f-bf9e-5cbd54491120"
   },
   "outputs": [],
   "source": [
    "class PositionwiseLSTMFF(torch.nn.Module):\n",
    "    def __init__(self, d_model, d_inner, dropout, pre_lnorm=False):\n",
    "        super(PositionwiseLSTMFF, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_inner = d_inner\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.CoreNet = nn.Sequential(\n",
    "            nn.Linear(d_model, d_inner), \n",
    "            nn.LSTMCell(d_model, d_inner),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_inner, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.pre_lnorm = pre_lnorm\n",
    "\n",
    "    def forward(self, inp):\n",
    "        if self.pre_lnorm:\n",
    "            # layer normalization + positionwise feed-forward\n",
    "            core_out = self.CoreNet(self.layer_norm(inp))\n",
    "\n",
    "            # residual connection\n",
    "            output = core_out + inp\n",
    "        else:\n",
    "            # positionwise feed-forward\n",
    "            core_out = self.CoreNet(inp)\n",
    "\n",
    "            # residual connection + layer normalization\n",
    "            output = self.layer_norm(inp + core_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "8c4c4c1e-5353-4802-8e6d-fb3eb18466c1",
    "_uuid": "e5e18176-1e1e-44a8-b354-3f92eea92e1c"
   },
   "outputs": [],
   "source": [
    "class PositionwiseGRUFF(torch.nn.Module):\n",
    "    def __init__(self, d_model, d_inner, dropout, pre_lnorm=False):\n",
    "        super(PositionwiseGRUFF, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_inner = d_inner\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.CoreNet = nn.Sequential(\n",
    "            nn.Linear(d_model, d_inner), \n",
    "            nn.GRUCell(d_model, d_inner),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_inner, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.pre_lnorm = pre_lnorm\n",
    "\n",
    "    def forward(self, inp):\n",
    "        if self.pre_lnorm:\n",
    "            # layer normalization + positionwise feed-forward\n",
    "            core_out = self.CoreNet(self.layer_norm(inp))\n",
    "\n",
    "            # residual connection\n",
    "            output = core_out + inp\n",
    "        else:\n",
    "            # positionwise feed-forward\n",
    "            core_out = self.CoreNet(inp)\n",
    "\n",
    "            # residual connection + layer normalization\n",
    "            output = self.layer_norm(inp + core_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "4e4b5c2b-f173-4a8e-adf8-810d832c66ba",
    "_kg_hide-input": true,
    "_uuid": "0fef0944-98a7-43bb-9ccc-4a828ef10c42"
   },
   "outputs": [],
   "source": [
    "# Create Attention mask\n",
    "def create_mask(qlen, mlen, dtype=torch.float32, same_length=False):\n",
    "      \"\"\"Creates attention mask when single-side context allowed only.\"\"\"\n",
    "      attn_mask = torch.ones([qlen, qlen], dtype=dtype)\n",
    "      mask_u = torch.triu(attn_mask, 0, -1)\n",
    "      mask_dia = torch.triu(attn_mask, 0, 0)\n",
    "      attn_mask_pad = torch.zeros([qlen, mlen], dtype=dtype)\n",
    "      ret = torch.concat([attn_mask_pad, mask_u - mask_dia], 1)\n",
    "      if same_length:\n",
    "        mask_l = torch.triu(attn_mask, -1, 0)\n",
    "        ret = torch.concat([ret[:, :qlen] + mask_l - mask_dia, ret[:, qlen:]], 1)\n",
    "\n",
    "      return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "393b507b-5cb4-4619-99ac-cebd5601bbd6",
    "_uuid": "a821b007-65d1-4e62-998a-55ab5bab3316"
   },
   "source": [
    "### Embeddings and attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "05bd486a-6d14-4ec6-aa49-9e9a706572ef",
    "_kg_hide-input": true,
    "_uuid": "61ded353-0c12-4e33-92e1-4f155e65ab09"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(Module):\n",
    "  def __init__(self, dim, **kwargs):\n",
    "    super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "    self.dim = dim\n",
    "\n",
    "    \"\"\"Constructs inversed frequency vector for positional embedding layer.\"\"\"\n",
    "    self.inv_freq = 1.0 / (10000.0**(torch.range(0, 19380, 10.0) / self.dim))\n",
    "\n",
    "  def forward(self, pos_seq, batch_size):\n",
    "    \"\"\"Implements call() for the layer.\"\"\"\n",
    "    sinusoid_inp = torch.einsum('i,d->id', pos_seq, self.inv_freq)\n",
    "    pos_emb = torch.cat([torch.sin(sinusoid_inp), torch.cos(sinusoid_inp)], -1)\n",
    "    pos_emb = pos_emb[:, None, :]\n",
    "\n",
    "    if batch_size is not None:\n",
    "      pos_emb = tile(pos_emb, 2, self.dim)\n",
    "\n",
    "    return pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "599b167d-1325-4b85-b6c7-5ce5900c564e",
    "_kg_hide-input": true,
    "_uuid": "c7eab340-72da-403f-8722-a8275d297ec3"
   },
   "outputs": [],
   "source": [
    "## Took this from the TF GitHub repo and translated into Pytorch ##\n",
    "class RelativeAttention(Module):\n",
    "  \"\"\"Core calculations for relative attention.\"\"\"\n",
    "\n",
    "  def __init__(self, dropout_att, scale):\n",
    "    super(RelativeAttention, self).__init__()\n",
    "    self.scale = scale\n",
    "    self.dropout_att = dropout_att\n",
    "\n",
    "  def build(self, unused_input_shapes):\n",
    "    self.attention_probs_dropout = torch.nn.Dropout(\n",
    "        p=self.dropout_att)\n",
    "\n",
    "    super(RelativeAttention, self).build(unused_input_shapes)\n",
    "\n",
    "  def call(self, q_head, k_head_h, v_head_h, k_head_r, seg_embed, seg_mat,\n",
    "           r_w_bias, r_r_bias, r_s_bias, attn_mask):\n",
    "    # content based attention score\n",
    "    ac = torch.einsum('ibnd,jbnd->ijbn', q_head + r_w_bias, k_head_h)\n",
    "\n",
    "    # position based attention score\n",
    "    bd = torch.einsum('ibnd,jbnd->ijbn', q_head + r_r_bias, k_head_r)\n",
    "    bd = rel_shift(bd, klen=tf.shape(ac)[1])\n",
    "\n",
    "    # segment-based attention score\n",
    "    if seg_mat is None:\n",
    "      ef = 0\n",
    "    else:\n",
    "      ef = torch.einsum('ibnd,snd->isbn', q_head + r_s_bias, seg_embed)\n",
    "      tgt_shape = torch.shape(bd)\n",
    "      ef = torch.where(\n",
    "          torch.Tensor(np.broadcast_to(torch.expand_dims(seg_mat, 3), tgt_shape)),\n",
    "          torch.Tensor(np.broadcast_to(ef[:, 1:, :, :], tgt_shape)),\n",
    "          torch.Tensor(np.broadcast_to(ef[:, :1, :, :], tgt_shape)))\n",
    "\n",
    "    # merges attention scores and performs masking\n",
    "    attn_score = (ac + bd + ef) * self.scale\n",
    "    if attn_mask is not None:\n",
    "      attn_score = attn_score - 1e30 * attn_mask\n",
    "\n",
    "    # attention probability\n",
    "    attn_prob = functional.softmax(attn_score, 1)\n",
    "    attn_prob = self.attention_probs_dropout(attn_prob)\n",
    "\n",
    "    # attention output\n",
    "    attn_vec = torch.einsum('ijbn,jbnd->ibnd', attn_prob, v_head_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "d983bc7d-9acd-4141-9d4e-a4341f9953e9",
    "_kg_hide-input": true,
    "_uuid": "0a2a3b01-6411-4d64-b654-2f8a52003cec"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttn(torch.nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_head, dropout, dropatt=0, \n",
    "                 pre_lnorm=False):\n",
    "        super(MultiHeadAttn, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_head = d_head\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.q_net = nn.Linear(d_model, n_head * d_head, bias=False)\n",
    "        self.kv_net = nn.Linear(d_model, 2 * n_head * d_head, bias=False)\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.dropatt = nn.Dropout(dropatt)\n",
    "        self.o_net = nn.Linear(n_head * d_head, d_model, bias=False)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.scale = 1 / (d_head ** 0.5)\n",
    "\n",
    "        self.pre_lnorm = pre_lnorm\n",
    "\n",
    "    def forward(self, h, attn_mask=None, mems=None):\n",
    "        ##### multihead attention\n",
    "        # [hlen x bsz x n_head x d_head]\n",
    "\n",
    "        if mems is not None:\n",
    "            c = torch.cat([mems, h], 0)\n",
    "        else:\n",
    "            c = h\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            ##### layer normalization\n",
    "            c = self.layer_norm(c)\n",
    "\n",
    "        head_q = self.q_net(h)\n",
    "        head_k, head_v = torch.chunk(self.kv_net(c), 2, -1)\n",
    "\n",
    "        head_q = head_q.view(h.size(0), h.size(1), self.n_head, self.d_head)\n",
    "        head_k = head_k.view(c.size(0), c.size(1), self.n_head, self.d_head)\n",
    "        head_v = head_v.view(c.size(0), c.size(1), self.n_head, self.d_head)\n",
    "\n",
    "        # [qlen x klen x bsz x n_head]\n",
    "        attn_score = torch.einsum('ibnd,jbnd->ijbn', (head_q, head_k))\n",
    "        attn_score.mul_(self.scale)\n",
    "        if attn_mask is not None and attn_mask.any().item():\n",
    "            if attn_mask.dim() == 2:\n",
    "                attn_score.masked_fill_(attn_mask[None,:,:,None], -float('inf'))\n",
    "            elif attn_mask.dim() == 3:\n",
    "                attn_score.masked_fill_(attn_mask[:,:,:,None], -float('inf'))\n",
    "\n",
    "        # [qlen x klen x bsz x n_head]\n",
    "        attn_prob = F.softmax(attn_score, dim=1)\n",
    "        attn_prob = self.dropatt(attn_prob)\n",
    "\n",
    "        # [qlen x klen x bsz x n_head] + [klen x bsz x n_head x d_head] -> [qlen x bsz x n_head x d_head]\n",
    "        attn_vec = torch.einsum('ijbn,jbnd->ibnd', (attn_prob, head_v))\n",
    "        attn_vec = attn_vec.contiguous().view(\n",
    "            attn_vec.size(0), attn_vec.size(1), self.n_head * self.d_head)\n",
    "\n",
    "        ##### linear projection\n",
    "        attn_out = self.o_net(attn_vec)\n",
    "        attn_out = self.drop(attn_out)\n",
    "\n",
    "        if self.pre_lnorm:\n",
    "            ##### residual connection\n",
    "            output = h + attn_out\n",
    "        else:\n",
    "            ##### residual connection + layer normalization\n",
    "            output = self.layer_norm(h + attn_out)\n",
    "\n",
    "        return output\n",
    "\n",
    "class RelMultiHeadAttn(torch.nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_head, dropout, dropatt=0,\n",
    "                 tgt_len=None, ext_len=None, mem_len=None, pre_lnorm=False):\n",
    "        super(RelMultiHeadAttn, self).__init__()\n",
    "\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_head = d_head\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.qkv_net = nn.Linear(d_model, 3 * n_head * d_head, bias=False)\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.dropatt = nn.Dropout(dropatt)\n",
    "        self.o_net = nn.Linear(n_head * d_head, d_model, bias=False)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.scale = 1 / (d_head ** 0.5)\n",
    "\n",
    "        self.pre_lnorm = pre_lnorm\n",
    "\n",
    "    def _parallelogram_mask(self, h, w, left=False):\n",
    "        mask = torch.ones((h, w)).byte()\n",
    "        m = min(h, w)\n",
    "        mask[:m,:m] = torch.triu(mask[:m,:m])\n",
    "        mask[-m:,-m:] = torch.tril(mask[-m:,-m:])\n",
    "\n",
    "        if left:\n",
    "            return mask\n",
    "        else:\n",
    "            return mask.flip(0)\n",
    "\n",
    "    def _shift(self, x, qlen, klen, mask, left=False):\n",
    "        if qlen > 1:\n",
    "            zero_pad = torch.zeros((x.size(0), qlen-1, x.size(2), x.size(3)),\n",
    "                                    device=x.device, dtype=x.dtype)\n",
    "        else:\n",
    "            zero_pad = torch.zeros(0, device=x.device, dtype=x.dtype)\n",
    "\n",
    "        if left:\n",
    "            mask = mask.flip(1)\n",
    "            x_padded = torch.cat([zero_pad, x], dim=1).expand(qlen, -1, -1, -1)\n",
    "        else:\n",
    "            x_padded = torch.cat([x, zero_pad], dim=1).expand(qlen, -1, -1, -1)\n",
    "\n",
    "        x = x_padded.masked_select(mask[:,:,None,None]) \\\n",
    "                    .view(qlen, klen, x.size(2), x.size(3))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _rel_shift(self, x, zero_triu=False):\n",
    "        zero_pad = torch.zeros((x.size(0), 1, *x.size()[2:]),\n",
    "                               device=x.device, dtype=x.dtype)\n",
    "        x_padded = torch.cat([zero_pad, x], dim=1)\n",
    "\n",
    "        x_padded = x_padded.view(x.size(1) + 1, x.size(0), *x.size()[2:])\n",
    "\n",
    "        x = x_padded[1:].view_as(x)\n",
    "\n",
    "        if zero_triu:\n",
    "            ones = torch.ones((x.size(0), x.size(1)))\n",
    "            x = x * torch.tril(ones, x.size(1) - x.size(0))[:,:,None,None]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, w, r, attn_mask=None, mems=None):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "4316a3a6-93fb-42f9-8484-52f794b49920",
    "_kg_hide-input": true,
    "_uuid": "d1621607-336c-4200-b071-02bc7dc613dc"
   },
   "outputs": [],
   "source": [
    "def CBR(x, out_layer, kernel, stride, dilation):\n",
    "    x = torch.nn.Conv1d(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "    x = torch.nn.BatchNormalization()(x)\n",
    "    x = torch.nn.functional.Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def se_block(x_in, layer_n):\n",
    "    x = torch.nn.GlobalAveragePooling1D()(x_in)\n",
    "    x = torch.nn.Dense(layer_n//8, activation=\"relu\")(x)\n",
    "    x = torch.nn.Dense(layer_n, activation=\"sigmoid\")(x)\n",
    "    x_out=torch.nn.Multiply()([x_in, x])\n",
    "    return x_out\n",
    "\n",
    "def resblock(x_in, layer_n, kernel, dilation, use_se=True):\n",
    "    x = CBR(x_in, layer_n, kernel, 1, dilation)\n",
    "    x = CBR(x, layer_n, kernel, 1, dilation)\n",
    "    if use_se:\n",
    "        x = se_block(x, layer_n)\n",
    "    x = torch.nn.Add()([x_in, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "f73e946e-f134-4aa6-8d53-bf5363f2566f",
    "_kg_hide-input": true,
    "_uuid": "8011880b-1257-4d70-8b63-bf2b1cd0b259"
   },
   "outputs": [],
   "source": [
    "class TimeDistributed(torch.nn.Module):\n",
    "    def __init__(self, layer, time_steps, *args):        \n",
    "        super(TimeDistributed, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([layer(*args) for i in range(time_steps)])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size, time_steps, C, H, W = x.size()\n",
    "        output = torch.tensor([])\n",
    "        for i in range(time_steps):\n",
    "          output_t = self.layers[i](x[:, i, :, :, :])\n",
    "          output_t  = y.unsqueeze(1)\n",
    "          output = torch.cat((output, output_t ), 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "622180e0-7b49-4b44-8bf9-7bc431d9cbb5",
    "_uuid": "bcde1595-f612-4171-9005-34b0d1410789"
   },
   "source": [
    "# Transformer Hybrid\n",
    "\n",
    "---\n",
    "\n",
    "Notes pending\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "99370d5f-cadf-47f7-ab3b-8f5b01f4d0f5",
    "_kg_hide-input": true,
    "_uuid": "c3d7eb99-0619-4864-850d-6c604c807222"
   },
   "outputs": [],
   "source": [
    "class TransformerXLHybridEncoder(torch.nn.Module):\n",
    "  def __init__(self,\n",
    "               n_token,\n",
    "               n_layer,\n",
    "               d_model,\n",
    "               n_head,\n",
    "               d_head,\n",
    "               d_inner,\n",
    "               dropout,\n",
    "               dropout_att,\n",
    "               attn_type,\n",
    "               bi_data,\n",
    "               is_training,\n",
    "               initializer,\n",
    "               mem_len=None,\n",
    "               same_length=False,\n",
    "               clamp_len=-1,\n",
    "               untie_r=False,\n",
    "               use_tpu=True,\n",
    "               reuse_len=None,\n",
    "               ff_activation='relu',\n",
    "               use_cls_mask=False,\n",
    "               **kwargs):\n",
    "\n",
    "    super(TransformerXLHybridEncoder, self).__init__(**kwargs)\n",
    "\n",
    "    self.n_token = n_token\n",
    "    self.initializer = initializer\n",
    "    self.attn_type = attn_type\n",
    "    self.n_layer = n_layer\n",
    "    self.d_model = d_model\n",
    "    self.n_head = n_head\n",
    "    self.d_head = d_head\n",
    "    self.d_inner = d_inner\n",
    "    self.ff_activation = ff_activation\n",
    "    self.untie_r = untie_r\n",
    "    self.use_tpu = use_tpu\n",
    "    self.dropout = dropout\n",
    "    self.dropout_att = dropout_att\n",
    "\n",
    "    self.mem_len = mem_len\n",
    "    self.reuse_len = reuse_len\n",
    "    self.bi_data = bi_data\n",
    "    self.clamp_len = clamp_len\n",
    "    self.same_length = same_length\n",
    "    self.use_cls_mask = use_cls_mask\n",
    "\n",
    "  def build(self, unused_input_shapes):\n",
    "    \n",
    "    torch_float = torch.float32\n",
    "    tf_float = torch_float\n",
    "    self.inp = torch.nn.Input((64, 1))\n",
    "    self.cbr = CBR(self.inp, 64, 7, 1, 1)\n",
    "    self.embedding_lookup = EmbeddingLookup(\n",
    "        n_token=self.n_token,\n",
    "        d_embed=self.d_model,\n",
    "        initializer=self.initializer,\n",
    "        dtype=self.tf_float,\n",
    "        name='embedding1')\n",
    "\n",
    "    self.h_dropout = torch.nn.Dropout(p=self.dropout)\n",
    "    self.g_dropout = torch.nn.Dropout(p=self.dropout)\n",
    "\n",
    "    if self.untie_r:\n",
    "      self.r_w_bias = (\n",
    "          self.add_weight(\n",
    "              'r_w_bias',\n",
    "              shape=[self.n_layer, self.n_head, self.d_head],\n",
    "              dtype=self.torch_float,\n",
    "              initializer=self.initializer))\n",
    "      self.r_r_bias = (\n",
    "          self.add_weight(\n",
    "              'r_r_bias',\n",
    "              shape=[self.n_layer, self.n_head, self.d_head],\n",
    "              dtype=self.torch_float,\n",
    "              initializer=self.initializer))\n",
    "      self.r_s_bias = (\n",
    "          self.add_weight(\n",
    "              'r_s_bias',\n",
    "              shape=[self.n_layer, self.n_head, self.d_head],\n",
    "              dtype=self.torch_float,\n",
    "              initializer=self.initializer))\n",
    "    else:\n",
    "      self.r_w_bias = (\n",
    "          self.add_weight(\n",
    "              'r_w_bias',\n",
    "              shape=[self.n_head, self.d_head],\n",
    "              dtype=self.torch_float,\n",
    "              initializer=self.initializer))\n",
    "      self.r_r_bias = (\n",
    "          self.add_weight(\n",
    "              'r_r_bias',\n",
    "              shape=[self.n_head, self.d_head],\n",
    "              dtype=self.torch_float,\n",
    "              initializer=self.initializer))\n",
    "      self.r_s_bias = (\n",
    "          self.add_weight(\n",
    "              'r_s_bias', [self.n_head, self.d_head],\n",
    "              dtype=self.torch_float,\n",
    "              initializer=self.initializer))\n",
    "\n",
    "    self.seg_embed = self.add_weight(\n",
    "        'seg_embed', [self.n_layer, 2, self.n_head, self.d_head],\n",
    "        dtype=self.torch_float,\n",
    "        initializer=self.initializer)\n",
    "\n",
    "    self.mask_emb = self.add_weight(\n",
    "        'mask_emb/mask_emb', shape=[1, 1, self.d_model], dtype=self.torch_float)\n",
    "\n",
    "    self.emb_dropout = torch.nn.Dropout(p=self.dropout)\n",
    "    self.fwd_position_embedding = PositionalEmbedding(self.d_model)\n",
    "    self.fwd_td                 = TimeDistributed(self.fwd_position_embedding, time_steps=20)\n",
    "    self.fwd_lstm               = torch.nn.LSTM(128)(self.fwd_td)\n",
    "    self.hidden_vect_1 = (\n",
    "        Variable(torch.zeros(1, 1, hidden_size)),\n",
    "        Variable(torch.zeros(1, 1, hidden_size)))\n",
    "    self.output1, self.hidden1 = self.fwd_lstm(Variable(torch.rand(1, 5, 10)), hidden_vect_1)\n",
    "    self.bwd_position_embedding = PositionalEmbedding(self.d_model)\n",
    "    self.bwd_td                 = TimeDistributed(self.bwd_position_embedding, time_steps=20)\n",
    "    self.bwd_lstm               = torch.nn.LSTM(128)(self.bwd_td)\n",
    "    self.hidden_vect_1 = (\n",
    "        Variable(torch.zeros(1, 1, hidden_size)),\n",
    "        Variable(torch.zeros(1, 1, hidden_size)))\n",
    "    self.output2, self.hidden2 = self.bwd_lstm(Variable(torch.rand(1, 5, 10)), hidden_vect_1)\n",
    "\n",
    "    self.rel_multihead_layers = []\n",
    "    self.h_positionwise_ffn_layers = []\n",
    "    self.layer_norm_layers = []\n",
    "    for i in range(self.n_layer):\n",
    "      self.rel_multihead_layers.append(\n",
    "          RelMultiHeadAttn(\n",
    "              d_model=self.d_model,\n",
    "              dropout=self.dropout,\n",
    "              n_head=self.n_head,\n",
    "              d_head=self.d_head,\n",
    "              name='layer_%d/rel_attn' % (i)))\n",
    "      self.h_positionwise_ffn_layers.append(\n",
    "          PositionwiseFF(\n",
    "              d_model=self.d_model,\n",
    "              d_inner=self.d_inner,\n",
    "              dropout=self.dropout,\n",
    "              kernel_initializer=self.initializer,\n",
    "              activation_type=self.ff_activation,\n",
    "              name='layer_%d/ff' % (i)))\n",
    "\n",
    "    self.output_dropout = torch.nn.Dropout(p=self.dropout)\n",
    "    \n",
    "    def __call__(self,\n",
    "               inp_k,\n",
    "               seg_id=None,\n",
    "               input_mask=None,\n",
    "               mems=None,\n",
    "               perm_mask=None,\n",
    "               target_mapping=None,\n",
    "               inp_q=None,\n",
    "               **kwargs):\n",
    "    # Uses dict to feed inputs into call() in order to keep mems as a python\n",
    "    # list.\n",
    "        inputs = {\n",
    "        'inp_k': inp_k,\n",
    "        'seg_id': seg_id,\n",
    "        'input_mask': input_mask,\n",
    "        'mems': mems,\n",
    "        'perm_mask': perm_mask,\n",
    "        'target_mapping': target_mapping,\n",
    "        'inp_q': inp_q\n",
    "    }\n",
    "    return super(TransformerXLModel, self).__call__(inputs, **kwargs)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    \"\"\"Implements call() for the layer.\"\"\"\n",
    "    inp_k = inputs['inp_k']\n",
    "    seg_id = inputs['seg_id']\n",
    "    input_mask = inputs['input_mask']\n",
    "    mems = inputs['mems']\n",
    "    perm_mask = inputs['perm_mask']\n",
    "    target_mapping = inputs['target_mapping']\n",
    "    inp_q = inputs['inp_q']\n",
    "\n",
    "    new_mems = []\n",
    "\n",
    "    bsz = torch.shape(inp_k)[1]\n",
    "\n",
    "    qlen = inp_k.shape.as_list()[0]\n",
    "\n",
    "    mlen = mems[0].shape.as_list()[0] if mems is not None else 0\n",
    "    klen = mlen + qlen\n",
    "\n",
    "    ##### Attention mask\n",
    "    # causal attention mask\n",
    "    if self.attn_type == 'uni':\n",
    "      attn_mask = _create_mask(qlen, mlen, self.tf_float, self.same_length)\n",
    "      # pylint: enable=protected-access\n",
    "      attn_mask = attn_mask[:, :, None, None]\n",
    "    elif self.attn_type == 'bi':\n",
    "      attn_mask = None\n",
    "    else:\n",
    "      raise ValueError('Unsupported attention type: {}'.format(self.attn_type))\n",
    "\n",
    "    # data mask: input mask & perm mask\n",
    "    if input_mask is not None and perm_mask is not None:\n",
    "      data_mask = input_mask[None] + perm_mask\n",
    "\n",
    "    elif input_mask is not None and perm_mask is None:\n",
    "      data_mask = input_mask[None]\n",
    "    elif input_mask is None and perm_mask is not None:\n",
    "      data_mask = perm_mask\n",
    "    else:\n",
    "      data_mask = None\n",
    "\n",
    "    if data_mask is not None:\n",
    "      # all mems can be attended to\n",
    "      mems_mask = torch.zeros([tf.shape(data_mask)[0], mlen, bsz],\n",
    "                           dtype=self.tf_float)\n",
    "      data_mask = torch.cat([mems_mask, data_mask], 1)\n",
    "      if attn_mask is None:\n",
    "        attn_mask = data_mask[:, :, :, None]\n",
    "      else:\n",
    "        attn_mask += data_mask[:, :, :, None]\n",
    "\n",
    "    if attn_mask is not None:\n",
    "      attn_mask = torch.cast(attn_mask > 0, dtype=self.tf_float)\n",
    "\n",
    "    if attn_mask is not None:\n",
    "      non_tgt_mask = -torch.eye(qlen, dtype=self.tf_float)\n",
    "      non_tgt_mask = torch.cat(\n",
    "          [tf.zeros([qlen, mlen], dtype=self.tf_float), non_tgt_mask], axis=-1)\n",
    "      non_tgt_mask = torch.cast(\n",
    "          (attn_mask + non_tgt_mask[:, :, None, None]) > 0, dtype=self.tf_float)\n",
    "    else:\n",
    "      non_tgt_mask = None\n",
    "\n",
    "    word_emb_k = self.embedding_lookup(inp_k)\n",
    "\n",
    "    if inp_q is not None:\n",
    "      if target_mapping is not None:\n",
    "        word_emb_q = torch.tile(self.mask_emb,\n",
    "                             [tf.shape(target_mapping)[0], bsz, 1])\n",
    "      else:\n",
    "        inp_q_ext = inp_q[:, :, None]\n",
    "        word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k\n",
    "\n",
    "    output_h = self.h_dropout(word_emb_k)\n",
    "    output_g = None\n",
    "    if inp_q is not None:\n",
    "      output_g = self.g_dropout(word_emb_q)\n",
    "\n",
    "    ##### Segment embedding\n",
    "    if seg_id is not None:\n",
    "\n",
    "      # Convert `seg_id` to one-hot `seg_mat`\n",
    "\n",
    "      mem_pad = torch.zeros([mlen, bsz], dtype=tf.int32)\n",
    "\n",
    "      cat_id = torch.concat([mem_pad, seg_id], 0)\n",
    "\n",
    "      if self.use_cls_mask:\n",
    "        # `1` indicates not in the same segment [qlen x klen x bsz]\n",
    "        # seg_id: [qlen x bsz] & cat_id: [klen x bsz]\n",
    "        cls_mat = torch.logical_or(\n",
    "            torch.equal(seg_id, tf.constant([data_utils.SEG_ID_CLS]))[:, None],\n",
    "            torch.equal(cat_id, tf.constant([data_utils.SEG_ID_CLS]))[None, :])\n",
    "        seg_mat = torch.equal(seg_id[:, None], cat_id[None, :])\n",
    "        seg_mat = torch.logical_or(cls_mat, seg_mat)\n",
    "      else:\n",
    "        seg_mat = tf.logical_not(tf.equal(seg_id[:, None], cat_id[None, :]))\n",
    "    else:\n",
    "      seg_mat = None\n",
    "\n",
    "    dtype = self.tf_float\n",
    "    freq_seq = tf.range(0, self.d_model, 2.0)\n",
    "    if dtype is not None and dtype != tf.float32:\n",
    "      freq_seq = tf.cast(freq_seq, dtype=self.dtype)\n",
    "\n",
    "    if self.attn_type == 'bi':\n",
    "      beg, end = klen, -qlen\n",
    "    elif self.attn_type == 'uni':\n",
    "      beg, end = klen, -1\n",
    "    else:\n",
    "      raise ValueError('Unknown `attn_type` {}.'.format(self.attn_type))\n",
    "\n",
    "    if self.bi_data:\n",
    "      fwd_pos_seq = torch.range(beg, end, -1.0)\n",
    "      bwd_pos_seq = torch.range(-beg, -end, 1.0)\n",
    "\n",
    "      if dtype is not None and dtype != tf.float32:\n",
    "        fwd_pos_seq = torch.cast(fwd_pos_seq, dtype=dtype)\n",
    "        bwd_pos_seq = torxh.cast(bwd_pos_seq, dtype=dtype)\n",
    "\n",
    "      if self.clamp_len > 0:\n",
    "        fwd_pos_seq = torch.clip_by_value(fwd_pos_seq, -self.clamp_len,\n",
    "                                       self.clamp_len)\n",
    "        bwd_pos_seq = torch.clip_by_value(bwd_pos_seq, -self.clamp_len,\n",
    "                                       self.clamp_len)\n",
    "\n",
    "      if bsz is not None:\n",
    "        fwd_pos_emb = self.fwd_position_embedding(fwd_pos_seq, bsz // 2)\n",
    "        bwd_pos_emb = self.bwd_position_embedding(bwd_pos_seq, bsz // 2)\n",
    "      else:\n",
    "        fwd_pos_emb = self.fwd_position_embedding(fwd_pos_seq, None)\n",
    "        bwd_pos_emb = self.bwd_position_embedding(bwd_pos_seq, None)\n",
    "\n",
    "      pos_emb = tf.concat([fwd_pos_emb, bwd_pos_emb], axis=1)\n",
    "    else:\n",
    "      fwd_pos_seq = tf.range(beg, end, -1.0)\n",
    "      if dtype is not None and dtype != tf.float32:\n",
    "        fwd_pos_seq = tf.cast(fwd_pos_seq, dtype=dtype)\n",
    "      if self.clamp_len > 0:\n",
    "        fwd_pos_seq = tf.clip_by_value(fwd_pos_seq, -self.clamp_len,\n",
    "                                       self.lamp_len)\n",
    "\n",
    "      pos_emb = self.fwd_position_embedding(fwd_pos_seq, bsz)\n",
    "\n",
    "    pos_emb = self.emb_dropout(pos_emb)\n",
    "\n",
    "    if mems is None:\n",
    "      mems = [None] * self.n_layer\n",
    "    for i in range(self.n_layer):\n",
    "      # cache new mems\n",
    "      new_mems.append(\n",
    "          _cache_mem(output_h, mems[i], self.mem_len, self.reuse_len))\n",
    "      # pylint: enable=protected-access\n",
    "\n",
    "      # segment bias\n",
    "      if seg_id is None:\n",
    "        r_s_bias_i = None\n",
    "        seg_embed_i = None\n",
    "      else:\n",
    "        r_s_bias_i = self.r_s_bias if not self.untie_r else self.r_s_bias[i]\n",
    "        seg_embed_i = self.seg_embed[i]\n",
    "\n",
    "      ffn_layer = self.h_positionwise_ffn_layers[i]\n",
    "      attention_layer = self.rel_multihead_layers[i]\n",
    "      output_h, output_g = attention_layer(\n",
    "          h=output_h,\n",
    "          g=output_g,\n",
    "          r=pos_emb,\n",
    "          r_w_bias=self.r_w_bias if not self.untie_r else self.r_w_bias[i],\n",
    "          r_r_bias=self.r_r_bias if not self.untie_r else self.r_r_bias[i],\n",
    "          seg_mat=seg_mat,\n",
    "          r_s_bias=r_s_bias_i,\n",
    "          seg_embed=seg_embed_i,\n",
    "          attn_mask_h=non_tgt_mask,\n",
    "          attn_mask_g=attn_mask,\n",
    "          mems=mems[i],\n",
    "          target_mapping=target_mapping)\n",
    "      output_h = ffn_layer(output_h)\n",
    "      if output_g is not None:\n",
    "        output_g = ffn_layer(output_g)\n",
    "\n",
    "    if inp_q is not None:\n",
    "      output = output_g\n",
    "    else:\n",
    "      output = output_h\n",
    "\n",
    "    return output, new_mems, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "a541e9b3-d920-4dbb-b119-037ba588bf68",
    "_kg_hide-input": true,
    "_uuid": "ba143957-4f55-4826-9751-c9f5318377ea"
   },
   "outputs": [],
   "source": [
    "class AdaptiveEmbedding(torch.nn.Module):\n",
    "    def __init__(self, n_token, d_embed, d_proj, cutoffs, div_val=1,\n",
    "                 sample_softmax=False):\n",
    "        super(AdaptiveEmbedding, self).__init__()\n",
    "\n",
    "        self.n_token = n_token\n",
    "        self.d_embed = d_embed\n",
    "\n",
    "        self.cutoffs = [cutoffs] + [n_token]\n",
    "        self.div_val = div_val\n",
    "        self.d_proj = d_proj\n",
    "\n",
    "        self.emb_scale = d_proj ** 0.5\n",
    "\n",
    "        self.cutoff_ends = [0] + [self.cutoffs]\n",
    "\n",
    "        self.emb_layers = nn.ModuleList()\n",
    "        self.emb_projs = nn.ParameterList()\n",
    "        if div_val == 1:\n",
    "            for i in range(1,self.n_token):\n",
    "                self.emb_layers.append(\n",
    "                    nn.Embedding(n_token, d_embed, sparse=(sample_softmax > 0))\n",
    "                )\n",
    "            if d_proj != d_embed:\n",
    "                self.emb_projs.append(nn.Parameter(torch.Tensor(d_proj, d_embed)))\n",
    "        else:\n",
    "            for i in range(len(self.cutoffs)):\n",
    "                l_idx, r_idx = self.cutoff_ends[i], self.cutoff_ends[i+1]\n",
    "                d_emb_i = d_embed // (div_val ** i)\n",
    "                self.emb_layers.append(nn.Embedding(r_idx-l_idx, d_emb_i))\n",
    "                self.emb_projs.append(nn.Parameter(torch.Tensor(d_proj, d_emb_i)))\n",
    "\n",
    "    def forward(self, inp):\n",
    "        if self.div_val == 1:\n",
    "            for i in range(1,self.n_token):\n",
    "                embed = []\n",
    "                embed.append(self.emb_layers[i](inp))\n",
    "                if self.d_proj != self.d_embed:\n",
    "                    embed = F.linear(embed, self.emb_projs[0])\n",
    "        else:\n",
    "            param = next(self.parameters())\n",
    "            inp_flat = inp.view(-1)\n",
    "            emb_flat = torch.zeros([inp_flat.size(0), self.d_proj],\n",
    "                                   dtype=param.dtype, device=param.device)\n",
    "            for i in range(len(self.cutoffs)):\n",
    "                l_idx, r_idx = self.cutoff_ends[i], self.cutoff_ends[i + 1]\n",
    "\n",
    "                mask_i = (inp_flat >= l_idx) & (inp_flat < r_idx)\n",
    "                indices_i = mask_i.nonzero().squeeze()\n",
    "\n",
    "                if indices_i.numel() == 0:\n",
    "                    continue\n",
    "\n",
    "                inp_i = inp_flat.index_select(0, indices_i) - l_idx\n",
    "                emb_i = self.emb_layers[i](inp_i)\n",
    "                emb_i = F.linear(emb_i, self.emb_projs[i])\n",
    "\n",
    "                emb_flat.index_copy_(0, indices_i, emb_i)\n",
    "\n",
    "            embed = emb_flat.view(*inp.size(), self.d_proj)\n",
    "\n",
    "        embed.mul_(self.emb_scale)\n",
    "\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "26756ee2-8a2e-4627-b926-37a4530e5e6c",
    "_kg_hide-input": true,
    "_uuid": "df33cd3b-e2a6-441b-ac0d-a8b6a66a8b7e"
   },
   "outputs": [],
   "source": [
    "class GPT2OptimizedDecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_head, d_inner, dropout, hidden_size, **kwargs):\n",
    "        super(GPT2OptimizedDecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_attn = MultiHeadAttn(n_head, d_model, d_head, dropout, **kwargs)\n",
    "        self.pos_ff = PositionwiseLSTMFF(d_model, d_inner, dropout,\n",
    "                                     pre_lnorm=kwargs.get('pre_lnorm'))\n",
    "        self.dec_attn2 = MultiHeadAttn(n_head, d_model, d_head, dropout, **kwargs)\n",
    "        self.pos_gru_ff = PositionwiseGRUFF(d_model, d_inner, dropout,\n",
    "                                     pre_lnorm=kwargs.get('pre_lnorm'))\n",
    "        \n",
    "    \n",
    "        ###### ATTENTION #####################################\n",
    "        # self.dec_attn3 = GPT2ParallelSelfAttn(hidden_size, )\n",
    "        ###MUST WORK ON GPT2 ATTENTION########################\n",
    "\n",
    "    def forward(self, dec_inp, dec_attn_mask=None, mems=None):\n",
    "\n",
    "        output = self.dec_attn(dec_inp, attn_mask=dec_attn_mask,\n",
    "                               mems=mems)\n",
    "        output = self.pos_gru_ff(output)\n",
    "        output = self.dec_attn2(dec_inp, attn_mask=dec_attn_mask,\n",
    "                               mems=mems)\n",
    "        output = self.pos_ff(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class RelLearnableDecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_head, d_inner, dropout,\n",
    "                 **kwargs):\n",
    "        super(RelLearnableDecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_attn = RelLearnableMultiHeadAttn(n_head, d_model, d_head,\n",
    "                                                  dropout, **kwargs)\n",
    "        self.pos_gru_ff = PositionwiseGRUFF(d_model, d_inner, dropout,\n",
    "                                     pre_lnorm=kwargs.get('pre_lnorm'))\n",
    "        self.dec_attn2 = RelLearnableMultiHeadAttn(n_head, d_model, d_head,\n",
    "                                                  dropout, **kwargs)\n",
    "        self.pos_ff = PositionwiseLSTMFF(d_model, d_inner, dropout,\n",
    "                                     pre_lnorm=kwargs.get('pre_lnorm'))\n",
    "\n",
    "    def forward(self, dec_inp, r_emb, r_w_bias, r_bias, dec_attn_mask=None, mems=None):\n",
    "\n",
    "        output = self.dec_attn(dec_inp, r_emb, r_w_bias, r_bias,\n",
    "                               attn_mask=dec_attn_mask,\n",
    "                               mems=mems)\n",
    "        output = self.pos_gru_ff(output)\n",
    "        output = self.dec_attn2(dec_inp, r_emb, r_w_bias, r_bias,\n",
    "                               attn_mask=dec_attn_mask,\n",
    "                               mems=mems)\n",
    "        output = self.pos_ff(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class RelPartialLearnableDecoderLayer(torch.nn.Module):\n",
    "    def __init__(self, n_head, d_model, d_head, d_inner, dropout,\n",
    "                 **kwargs):\n",
    "        super(RelPartialLearnableDecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_attn = RelPartialLearnableMultiHeadAttn(n_head, d_model,\n",
    "                                                         d_head, dropout,\n",
    "                                                         **kwargs)\n",
    "        self.pos_ff = PositionwiseLSTMFF(d_model, d_inner, dropout,\n",
    "                                     pre_lnorm=kwargs.get('pre_lnorm'))\n",
    "\n",
    "    def forward(self, dec_inp, r, r_w_bias, r_r_bias, dec_attn_mask=None, mems=None):\n",
    "\n",
    "        output = self.dec_attn(dec_inp, r, r_w_bias, r_r_bias,\n",
    "                               attn_mask=dec_attn_mask,\n",
    "                               mems=mems)\n",
    "        output = self.pos_ff(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "a7e832ea-0b02-4605-833c-39ec69e24579",
    "_kg_hide-input": true,
    "_uuid": "734a9b4d-be95-4145-a48c-47c74220b019"
   },
   "outputs": [],
   "source": [
    "class Transformer(torch.nn.Module):\n",
    "    def __init__(self, n_token, n_layer, n_head, d_model, d_head, d_inner,\n",
    "                 dropout, dropatt, dtype, attention_dropout_prob, output_dropout_prob, \n",
    "                 init_method, bi_data, tie_weight=True, d_embed=None,\n",
    "                 div_val=1, tie_projs=[False], pre_lnorm=False,\n",
    "                 tgt_len=10, ext_len=10, mem_len=10,\n",
    "                 cutoffs=[], adapt_inp=False,\n",
    "                 same_length=False, attn_type=2, clamp_len=-1,\n",
    "                 sample_softmax=-1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.n_token = n_token\n",
    "\n",
    "        d_embed = d_model if d_embed is None else d_embed\n",
    "        self.d_embed = d_embed\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_head\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.tie_weight = tie_weight\n",
    "        self.tie_projs = tie_projs\n",
    "        self.div_val = div_val\n",
    "\n",
    "        self.n_layer = n_layer\n",
    "\n",
    "        self.tgt_len = tgt_len\n",
    "        self.mem_len = mem_len\n",
    "        self.ext_len = ext_len\n",
    "        self.max_klen = tgt_len + ext_len + mem_len\n",
    "\n",
    "        self.attn_type = attn_type\n",
    "        \n",
    "        self.word_emb = PositionalEmbedding(d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(\n",
    "            TransformerXLHybridEncoder(\n",
    "               n_token,\n",
    "               n_layer,\n",
    "               d_model,\n",
    "               n_head,\n",
    "               d_head,\n",
    "               d_inner,\n",
    "               dropout,\n",
    "               dropatt,\n",
    "               bi_data,\n",
    "               attn_type,\n",
    "               is_training=True,\n",
    "               initializer=torch.optim.SGD,\n",
    "            )\n",
    "        )\n",
    "        self.layers.append(\n",
    "            TransformerXLHybridEncoder(\n",
    "               n_token,\n",
    "               n_layer,\n",
    "               d_model,\n",
    "               n_head,\n",
    "               d_head,\n",
    "               d_inner,\n",
    "               dropout,\n",
    "               dropatt,\n",
    "               bi_data,               \n",
    "               attn_type,\n",
    "               is_training=True,\n",
    "               initializer=torch.optim.SGD,\n",
    "            )\n",
    "        )\n",
    "        self.layers.append(\n",
    "            TransformerXLHybridEncoder(\n",
    "               n_token,\n",
    "               n_layer,\n",
    "               d_model,\n",
    "               n_head,\n",
    "               d_head,\n",
    "               d_inner,\n",
    "               dropout,\n",
    "               dropatt,\n",
    "               bi_data,\n",
    "               attn_type,\n",
    "               is_training=True,\n",
    "               initializer=torch.optim.SGD,\n",
    "            )\n",
    "        )\n",
    "        # the default attention\n",
    "        if attn_type == 0:\n",
    "            for i in range(n_layer):\n",
    "                self.layers.append(\n",
    "                    RelPartialLearnableDecoderLayer(\n",
    "                        n_head, d_model, d_head, d_inner, dropout,\n",
    "                        tgt_len=tgt_len, ext_len=ext_len, mem_len=mem_len,\n",
    "                        dropatt=dropatt, pre_lnorm=pre_lnorm)\n",
    "                )\n",
    "        # learnable embeddings\n",
    "        elif attn_type == 1:\n",
    "            for i in range(n_layer):\n",
    "                self.layers.append(\n",
    "                    RelLearnableDecoderLayer(\n",
    "                        n_head, d_model, d_head, d_inner, dropout,\n",
    "                        tgt_len=tgt_len, ext_len=ext_len, mem_len=mem_len,\n",
    "                        dropatt=dropatt, pre_lnorm=pre_lnorm)\n",
    "                )\n",
    "        # absolute embeddings\n",
    "        elif attn_type in [2, 3]:\n",
    "            for i in range(n_layer):\n",
    "                self.layers.append(\n",
    "                    GPT2OptimizedDecoderLayer(\n",
    "                        n_head, d_model, d_head, d_inner, dropout,\n",
    "                        dropatt=dropatt, pre_lnorm=pre_lnorm, hidden_size=16)\n",
    "                )\n",
    "        \n",
    "        self.sample_softmax = sample_softmax\n",
    "        # use sampled softmax\n",
    "        if sample_softmax > 0:\n",
    "            self.out_layer = nn.Linear(d_model, n_token)\n",
    "            self.tie_weight = tie_weight\n",
    "            self.sampler = LogUniformSampler(n_token, sample_softmax)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # use adaptive softmax (including standard softmax)\n",
    "        else:\n",
    "            if tie_weight:\n",
    "                emb_layers = [i.weight for i in AdaptiveEmbedding(d_model, d_head, d_inner, n_head).emb_layers]\n",
    "            else:\n",
    "                emb_layers = None\n",
    "\n",
    "            emb_projs = AdaptiveEmbedding(d_model, d_head, d_inner, n_head).emb_projs\n",
    "\n",
    "        self.same_length = same_length\n",
    "        self.clamp_len = clamp_len\n",
    "\n",
    "        self._create_params()\n",
    "\n",
    "    def backward_compatible(self):\n",
    "        self.sample_softmax = -1\n",
    "    cutoffs=[]\n",
    "    \n",
    "    def _create_params(self):\n",
    "        # default attention\n",
    "        cutoffs=[]\n",
    "        if self.attn_type == 0:\n",
    "            self.pos_emb = AdaptiveEmbedding(self.n_token, self.d_embed, self.d_model, cutoffs,\n",
    "                                          div_val=self.div_val)\n",
    "            self.r_w_bias = nn.Parameter(torch.Tensor(self.n_head, self.d_head))\n",
    "            self.r_r_bias = nn.Parameter(torch.Tensor(self.n_head, self.d_head))\n",
    "        # learnable\n",
    "        elif self.attn_type == 1:\n",
    "            self.r_emb = nn.Parameter(torch.Tensor(\n",
    "                    self.n_layer, self.max_klen, self.n_head, self.d_head))\n",
    "            self.r_w_bias = nn.Parameter(torch.Tensor(\n",
    "                    self.n_layer, self.n_head, self.d_head))\n",
    "            self.r_bias = nn.Parameter(torch.Tensor(\n",
    "                    self.n_layer, self.max_klen, self.n_head))\n",
    "        # absolute standard\n",
    "        elif self.attn_type == 2:\n",
    "            self.pos_emb = PositionalEmbedding(self.d_model)\n",
    "        # absolute deeper SA\n",
    "        elif self.attn_type == 3:\n",
    "            self.r_emb = nn.Parameter(torch.Tensor(\n",
    "                    self.n_layer, self.max_klen, self.d_model))\n",
    "\n",
    "    def reset_length(self, tgt_len, ext_len, mem_len):\n",
    "        self.tgt_len = tgt_len\n",
    "        self.mem_len = mem_len\n",
    "        self.ext_len = ext_len\n",
    "\n",
    "    def init_mems(self):\n",
    "        if self.mem_len > 0:\n",
    "            mems = []\n",
    "            param = next(self.parameters())\n",
    "            for i in range(self.n_layer+1):\n",
    "                empty = torch.empty(0, dtype=param.dtype, device=param.device)\n",
    "                mems.append(empty)\n",
    "\n",
    "            return mems\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _update_mems(self, hids, mems, qlen, mlen):\n",
    "        # does not deal with None\n",
    "        if mems is None:\n",
    "            return None\n",
    "\n",
    "        # mems is not None\n",
    "        assert len(hids) == len(mems), 'len(hids) != len(mems)'\n",
    "\n",
    "        # There are `mlen + qlen` steps that can be cached into mems\n",
    "        # For the next step, the last `ext_len` of the `qlen` tokens\n",
    "        # will be used as the extended context. Hence, we only cache\n",
    "        # the tokens from `mlen + qlen - self.ext_len - self.mem_len`\n",
    "        # to `mlen + qlen - self.ext_len`.\n",
    "        with torch.no_grad():\n",
    "            new_mems = []\n",
    "            end_idx = mlen + max(0, qlen - 0 - self.ext_len)\n",
    "            beg_idx = max(0, end_idx - self.mem_len)\n",
    "            for i in range(len(hids)):\n",
    "\n",
    "                cat = torch.cat([mems[i], hids[i]], dim=0)\n",
    "                new_mems.append(cat[beg_idx:end_idx].detach())\n",
    "\n",
    "        return new_mems\n",
    "\n",
    "    def _forward(self, dec_inp, mems=None):\n",
    "        qlen, bsz = dec_inp.size()\n",
    "        true_size = 7\n",
    "\n",
    "        word_emb = PositionalEmbedding(dec_inp)\n",
    "\n",
    "        mlen = mems[0].size(0) if mems is not None else 0\n",
    "        klen = mlen + qlen\n",
    "\n",
    "        # absolute\n",
    "        if self.attn_type == 2:\n",
    "            pos_seq = torch.LongTensor(torch.arange(klen - 1, -1, -1.0, dtype=torch.long))\n",
    "            if self.clamp_len > 0:\n",
    "                pos_seq.clamp_(max=self.clamp_len)\n",
    "            pos_emb = self.pos_emb(pos_seq, 64)\n",
    "\n",
    "            core_out = self.drop(pos_emb[-qlen:])\n",
    "            hids = []\n",
    "            hids.append(core_out)\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                mems_i = None if mems is None else mems[i]\n",
    "                if mems_i is not None and len(mems_i) and i == 0:\n",
    "                    mems_i += pos_emb[:mlen]\n",
    "                core_out = core_out\n",
    "                hids.append(core_out)\n",
    "        elif self.attn_type == 3:\n",
    "            core_out = self.drop(word_emb)\n",
    "\n",
    "            hids.append(core_out)\n",
    "            for i, layer in enumerate(self.layers):\n",
    "                mems_i = None if mems is None else mems[i]\n",
    "                if mems_i is not None and len(mems_i) and mlen > 0:\n",
    "                    cur_emb = self.r_emb[i][:-qlen]\n",
    "                    cur_size = cur_emb.size(0)\n",
    "                    if cur_size < mlen:\n",
    "                        cur_emb_pad = cur_emb[0:1].expand(mlen-cur_size, -1, -1)\n",
    "                        cur_emb = torch.cat([cur_emb_pad, cur_emb], 0)\n",
    "                    else:\n",
    "                        cur_emb = cur_emb[-mlen:]\n",
    "                    mems_i += cur_emb.view(mlen, 1, -1)\n",
    "                core_out += self.r_emb[i][-qlen:].view(qlen, 1, -1)\n",
    "\n",
    "                core_out = layer(core_out, dec_attn_mask=dec_attn_mask,\n",
    "                                 mems=mems_i)\n",
    "                hids.append(core_out)\n",
    "\n",
    "        core_out = self.drop(core_out)\n",
    "\n",
    "        new_mems = self._update_mems(hids, mems, qlen, mlen)\n",
    "\n",
    "        return core_out, new_mems\n",
    "\n",
    "    def forward(self, data, target, mems):\n",
    "        # nn.DataParallel does not allow size(0) tensors to be broadcasted.\n",
    "        # So, have to initialize size(0) mems inside the model forward.\n",
    "        # Moreover, have to return new_mems to allow nn.DataParallel to piece\n",
    "        # them together.\n",
    "        if mems is None:\n",
    "            mems = self.init_mems()\n",
    "\n",
    "        tgt_len = target.size(0)\n",
    "        hidden, new_mems = self._forward(data, mems=None)\n",
    "\n",
    "        pred_hid = hidden[-tgt_len:]\n",
    "        if self.sample_softmax > 0 and self.training:\n",
    "            assert self.tie_weight\n",
    "            logit = sample_logits(self.word_emb, self.out_layer.bias, target,\n",
    "                                  pred_hid, self.sampler)\n",
    "            loss = -F.log_softmax(logit, -1)[:, :, 0]\n",
    "        else:\n",
    "            loss = self.crit(pred_hid.view(-1, pred_hid.size(-1)), target.view(-1))\n",
    "            loss = loss.view(tgt_len, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "12a7f44a-9250-4a0d-aceb-7d81bb6644b8",
    "_uuid": "79091dee-7e1b-438d-ac09-c4c7892887df"
   },
   "source": [
    "## Data wrangling (Credit to kkiller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "ef27fe44-33d5-4790-aadf-ff8c2b2f3de2",
    "_uuid": "d161bf26-963f-40d2-bf3a-773e3ee632e3"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/preprocessing-for-m5/training.csv')\n",
    "test = pd.read_csv('../input/preprocessing-for-m5/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b2daa496-02a1-44db-9ca7-f8350b66c0c5",
    "_uuid": "daf14886-5fd6-4e21-afe8-50bcd96df3d2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as T\n",
    "from sklearn.preprocessing import OneHotEncoder as OHE\n",
    "X_train, y_train = T(train,test_size=0.1)\n",
    "X_test, y_test = T(test,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "95b7746b-c277-43b8-b32c-eb34cb0d9589",
    "_uuid": "9eb761d8-3b62-4ea9-8318-05c7458efc05"
   },
   "outputs": [],
   "source": [
    "X = Transformer(\n",
    "    n_token=500,\n",
    "    n_layer=18,\n",
    "    n_head=8,\n",
    "    d_model=10,\n",
    "    d_head=8,\n",
    "    d_inner=12,\n",
    "    dropout=0.2,\n",
    "    dropatt=0.2,\n",
    "    dtype=torch.float32,\n",
    "    attention_dropout_prob=0.15,\n",
    "    output_dropout_prob=0.175,\n",
    "    init_method=torch.optim.SGD,\n",
    "    bi_data=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "27201d09-455c-428b-abdf-6165582c7add",
    "_uuid": "a55ccaac-5399-49d0-9d7b-1b5ae77439a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (word_emb): PositionalEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerXLHybridEncoder()\n",
       "    (1): TransformerXLHybridEncoder()\n",
       "    (2): TransformerXLHybridEncoder()\n",
       "    (3): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (4): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (5): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (6): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (7): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (8): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (9): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (10): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (11): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (12): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (13): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (14): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (15): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (16): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (17): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (18): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (19): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (20): GPT2OptimizedDecoderLayer(\n",
       "      (dec_attn): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_ff): PositionwiseLSTMFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): LSTMCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (dec_attn2): MultiHeadAttn(\n",
       "        (q_net): Linear(in_features=10, out_features=64, bias=False)\n",
       "        (kv_net): Linear(in_features=10, out_features=128, bias=False)\n",
       "        (drop): Dropout(p=0.2, inplace=False)\n",
       "        (dropatt): Dropout(p=0.2, inplace=False)\n",
       "        (o_net): Linear(in_features=64, out_features=10, bias=False)\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (pos_gru_ff): PositionwiseGRUFF(\n",
       "        (CoreNet): Sequential(\n",
       "          (0): Linear(in_features=10, out_features=12, bias=True)\n",
       "          (1): GRUCell(10, 12)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "          (4): Linear(in_features=12, out_features=10, bias=True)\n",
       "          (5): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pos_emb): PositionalEmbedding()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "ef2746cf-8a88-4fa3-8a88-4ec4d5419305",
    "_uuid": "77c87352-fb65-471b-a6be-b55ae5eff503"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(X.parameters(), lr=0.001, momentum=0.9)\n",
    "train = train.drop(['id'], axis=1)\n",
    "train = train.drop(['item_id'], axis=1)\n",
    "train = train.drop(['dept_id'], axis=1)\n",
    "train = train.drop(['cat_id'], axis=1)\n",
    "train = train.drop(['store_id'], axis=1)\n",
    "train = train.drop(['state_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "b93d9391-6f2a-4f25-ad7c-1895dffac04e",
    "_uuid": "377f4a07-6e8d-4c28-aeaa-44e7bd46ca54"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['id'], axis=1)\n",
    "X_train = X_train.drop(['item_id'], axis=1)\n",
    "X_train = X_train.drop(['dept_id'], axis=1)\n",
    "X_train = X_train.drop(['cat_id'], axis=1)\n",
    "X_train = X_train.drop(['store_id'], axis=1)\n",
    "X_train = X_train.drop(['state_id'], axis=1)\n",
    "y_train = y_train.drop(['id'], axis=1)\n",
    "y_train = y_train.drop(['item_id'], axis=1)\n",
    "y_train = y_train.drop(['dept_id'], axis=1)\n",
    "y_train = y_train.drop(['cat_id'], axis=1)\n",
    "y_train = y_train.drop(['store_id'], axis=1)\n",
    "y_train = y_train.drop(['state_id'], axis=1)\n",
    "X_train.to_csv('TRAIN_X.csv', index=False)\n",
    "del X_train\n",
    "y_train.to_csv('TRAIN_Y.csv', index=False)\n",
    "del y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
