{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRMSSE calculations without overhead\n",
    "\n",
    "This notebook is based on amazing [for_Japanese_beginner(with WRMSSE in LGBM))](https://www.kaggle.com/girmdshinsei/for-japanese-beginner-with-wrmsse-in-lgbm) and [RMSE and WRMSSE of a submission](https://www.kaggle.com/chameleontk/rmse-and-wrmsse-of-a-submission)\n",
    "\n",
    "Custom loss function requires quick calculations of WRMSSE. This notebook attempts to make a quick and clear WRMSEE calculation function with pickled S,W weights and pickled csr_matrix for swift rollups.\n",
    "\n",
    "Note: Difference in rolled up vectors is equal to their rolled up difference:\n",
    "\n",
    "\\begin{equation}\n",
    " Y\\times M - \\hat{Y}\\times M= (Y-\\hat{Y}) \\times M = D\n",
    "\\end{equation}\n",
    "\n",
    "The rest of the calculations are the same:\n",
    "\n",
    "\\begin{equation}\n",
    "WRMSSE = \\sum_{i=1}^{42840} \\left(\\frac{W_i}{\\sqrt{S_i}} \\times \\sqrt{\\sum{(D)^2}}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Note that the real weights are W/sqrt(S) this is important for weights evaluations. Besides a single precalulated weight can be used for faster calculations.\n",
    "Similar stuff in code:\n",
    "\n",
    "```\n",
    "roll_diff = rollup(preds.values-y_true.values)\n",
    "\n",
    "SW = W/np.sqrt(S)\n",
    "\n",
    "score = np.sum(\n",
    "                np.sqrt(\n",
    "                    np.mean(\n",
    "                        np.square(roll_diff)\n",
    "                            ,axis=1)) * SW)\n",
    "```\n",
    "\n",
    "Where S are weights based on sequence length, W are weights based on sales in USD for the 28 days.\n",
    "\n",
    "\n",
    "PS: The S and W weights has been compared with well tested [wrmsse-evaluator](https://www.kaggle.com/dhananjay3/wrmsse-evaluator-with-extra-features) and the original weights. Please let me know in the comments if you spot any mistakes.\n",
    "\n",
    "PPS: Please note: I have made a tiny mistake in WRMSSE function: should be /12 not x12 at the end. Updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5-Competitors-Guide-Final-10-March-2020.docx\r\n",
      "M5-Competitors-Guide-Final-10-March-2020.pdf\r\n",
      "\u001b[34mPyProg\u001b[m\u001b[m\r\n",
      "README.md\r\n",
      "\u001b[34mRProg\u001b[m\u001b[m\r\n",
      "\u001b[34madata\u001b[m\u001b[m\r\n",
      "\u001b[34mcatboost_info\u001b[m\u001b[m\r\n",
      "\u001b[34mrawdata\u001b[m\u001b[m\r\n",
      "\u001b[34mresults\u001b[m\u001b[m\r\n",
      "sw_df.pkl\r\n",
      "\u001b[34mus-natural-disaster-declarations\u001b[m\u001b[m\r\n",
      "~$-Competitors-Guide-Final-10-March-2020.docx\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix\n",
    "import gc\n",
    "\n",
    "import os\n",
    "path='/Users/x644435/Documents/Private/Kaggle/M5'\n",
    "os.chdir(path)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Memory reduction helper function:\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns: #columns\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: #numerics\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "All three datasets needed because we need to calculate sales in USD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "data_pass = 'rawdata/'\n",
    "\n",
    "# Sales quantities:\n",
    "sales = pd.read_csv(data_pass+'sales_train_validation.csv')\n",
    "\n",
    "# Calendar to get week number to join sell prices:\n",
    "calendar = pd.read_csv(data_pass+'calendar.csv')\n",
    "calendar = reduce_mem_usage(calendar)\n",
    "\n",
    "# Sell prices to calculate sales in USD:\n",
    "sell_prices = pd.read_csv(data_pass+'sell_prices.csv')\n",
    "sell_prices = reduce_mem_usage(sell_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate sales in USD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>sale</th>\n",
       "      <th>d</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sale_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>8.257812</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>0</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>1</td>\n",
       "      <td>d_1886</td>\n",
       "      <td>2.880859</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id store_id        item_id  sale       d  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     CA_1  HOBBIES_1_001     1  d_1886   \n",
       "1  HOBBIES_1_002_CA_1_validation     CA_1  HOBBIES_1_002     1  d_1886   \n",
       "2  HOBBIES_1_003_CA_1_validation     CA_1  HOBBIES_1_003     0  d_1886   \n",
       "3  HOBBIES_1_004_CA_1_validation     CA_1  HOBBIES_1_004     0  d_1886   \n",
       "4  HOBBIES_1_005_CA_1_validation     CA_1  HOBBIES_1_005     1  d_1886   \n",
       "\n",
       "   sell_price  sale_usd  \n",
       "0    8.257812  8.257812  \n",
       "1    3.970703  3.970703  \n",
       "2    2.970703  0.000000  \n",
       "3    4.640625  0.000000  \n",
       "4    2.880859  2.880859  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe with only last 28 days:\n",
    "cols = [\"d_{}\".format(i) for i in range(1914-28, 1914)]\n",
    "data = sales[[\"id\", 'store_id', 'item_id'] + cols]\n",
    "\n",
    "# To long form:\n",
    "data = data.melt(id_vars=[\"id\", 'store_id', 'item_id'], \n",
    "                 var_name=\"d\", value_name=\"sale\")\n",
    "\n",
    "# Add week of year column from 'calendar':\n",
    "data = pd.merge(data, calendar, how = 'left', \n",
    "                left_on = ['d'], right_on = ['d'])\n",
    "\n",
    "data = data[[\"id\", 'store_id', 'item_id', \"sale\", \"d\", \"wm_yr_wk\"]]\n",
    "\n",
    "# Add weekly price from 'sell_prices':\n",
    "data = data.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "data.drop(columns = ['wm_yr_wk'], inplace=True)\n",
    "\n",
    "# Calculate daily sales in USD:\n",
    "data['sale_usd'] = data['sale'] * data['sell_price']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollup Index & Matrix\n",
    "\n",
    "Build roll up matrix to easily compute aggregations.\n",
    "And build an index, so we always know whats where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42840, 30490)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30480</th>\n",
       "      <th>30481</th>\n",
       "      <th>30482</th>\n",
       "      <th>30483</th>\n",
       "      <th>30484</th>\n",
       "      <th>30485</th>\n",
       "      <th>30486</th>\n",
       "      <th>30487</th>\n",
       "      <th>30488</th>\n",
       "      <th>30489</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">11</th>\n",
       "      <th>HOUSEHOLD_2_516_WI_1_validation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_516_WI_2_validation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUSEHOLD_2_516_WI_3_validation</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0      1      2      3      4      \\\n",
       "level id                                                                   \n",
       "11    HOUSEHOLD_2_516_WI_1_validation      0      0      0      0      0   \n",
       "      HOUSEHOLD_2_516_WI_2_validation      0      0      0      0      0   \n",
       "      HOUSEHOLD_2_516_WI_3_validation      0      0      0      0      0   \n",
       "\n",
       "                                       5      6      7      8      9      ...  \\\n",
       "level id                                                                  ...   \n",
       "11    HOUSEHOLD_2_516_WI_1_validation      0      0      0      0      0  ...   \n",
       "      HOUSEHOLD_2_516_WI_2_validation      0      0      0      0      0  ...   \n",
       "      HOUSEHOLD_2_516_WI_3_validation      0      0      0      0      0  ...   \n",
       "\n",
       "                                       30480  30481  30482  30483  30484  \\\n",
       "level id                                                                   \n",
       "11    HOUSEHOLD_2_516_WI_1_validation      0      0      0      0      0   \n",
       "      HOUSEHOLD_2_516_WI_2_validation      0      0      0      0      0   \n",
       "      HOUSEHOLD_2_516_WI_3_validation      0      0      0      0      0   \n",
       "\n",
       "                                       30485  30486  30487  30488  30489  \n",
       "level id                                                                  \n",
       "11    HOUSEHOLD_2_516_WI_1_validation      0      0      0      0      0  \n",
       "      HOUSEHOLD_2_516_WI_2_validation      0      0      0      0      0  \n",
       "      HOUSEHOLD_2_516_WI_3_validation      0      0      0      0      0  \n",
       "\n",
       "[3 rows x 30490 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of categories combinations for aggregations as defined in docs:\n",
    "dummies_list = [sales.state_id, sales.store_id, \n",
    "                sales.cat_id, sales.dept_id, \n",
    "                sales.state_id +'_'+ sales.cat_id, sales.state_id +'_'+ sales.dept_id,\n",
    "                sales.store_id +'_'+ sales.cat_id, sales.store_id +'_'+ sales.dept_id, \n",
    "                sales.item_id, sales.state_id +'_'+ sales.item_id, sales.id]\n",
    "\n",
    "\n",
    "## First element Level_0 aggregation 'all_sales':\n",
    "dummies_df_list =[pd.DataFrame(np.ones(sales.shape[0]).astype(np.int8), \n",
    "                               index=sales.index, columns=['all']).T]\n",
    "\n",
    "# List of dummy dataframes:\n",
    "for i, cats in enumerate(dummies_list):\n",
    "    dummies_df_list +=[pd.get_dummies(cats, drop_first=False, dtype=np.int8).T]\n",
    "    \n",
    "# Concat dummy dataframes in one go:\n",
    "## Level is constructed for free.\n",
    "roll_mat_df = pd.concat(dummies_df_list, keys=list(range(12)), \n",
    "                        names=['level','id'])#.astype(np.int8, copy=False)\n",
    "\n",
    "# Save values as sparse matrix & save index for future reference:\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "print(roll_mat_csr.shape)\n",
    "roll_mat_df.tail(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump roll matrix to pickle:\n",
    "roll_mat_df.to_pickle('adata/roll_mat_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump roll matrix to csv:\n",
    "roll_mat_df.to_csv('adata/roll_mat_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Free some momory:\n",
    "del dummies_df_list, roll_mat_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S - sequence length weights\n",
    "It is a constant for the original dataset. It may be recalculated for every fold. IMHO it is overkill, but several people have weighty resasons for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fucntion to calculate S weights:\n",
    "def get_s(drop_days=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    drop_days: int, equals 0 by default, so S is calculated on all data.\n",
    "               If equals 28, last 28 days won't be used in calculating S.\n",
    "    \"\"\"\n",
    "    # Rollup sales:\n",
    "    d_name = ['d_' + str(i+1) for i in range(1913-drop_days)]\n",
    "    sales_train_val = roll_mat_csr * sales[d_name].values\n",
    "\n",
    "    no_sales = np.cumsum(sales_train_val, axis=1) == 0\n",
    "    sales_train_val = np.where(no_sales, np.nan, sales_train_val)\n",
    "\n",
    "    # Denominator of RMSSE / RMSSE\n",
    "    weight1 = np.nanmean(np.diff(sales_train_val,axis=1)**2,axis=1)\n",
    "    \n",
    "    return weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42840,)\n"
     ]
    }
   ],
   "source": [
    "S = get_s(drop_days=0)\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.26268315e+05, 5.14239651e+05, 5.17917913e+05, ...,\n",
       "       1.71293871e-01, 6.98666667e-02, 2.81004710e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S values from AGG & WRMSSE Evaluator:\n",
    "# array([3.26268315e+05, 5.14239651e+05, 5.17917913e+05, ...,\n",
    "#       1.71293871e-01, 6.98666667e-02, 2.81004710e-01])\n",
    "# Good match:\n",
    "S[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W - USD sales weights\n",
    "\n",
    "These are constant as they are arbitrary and predefined by business logic and have nothing to do with ML. (IMHO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functinon to calculate weights:\n",
    "def get_w(sale_usd):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Calculate the total sales in USD for each item id:\n",
    "    total_sales_usd = sale_usd.groupby(\n",
    "        ['id'], sort=False)['sale_usd'].apply(np.sum).values\n",
    "    \n",
    "    # Roll up total sales by ids to higher levels:\n",
    "    weight2 = roll_mat_csr * total_sales_usd\n",
    "    \n",
    "    return 12*weight2/np.sum(weight2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42840,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = get_w(data[['id','sale_usd']])\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.65350170e-02, 8.71179364e-02, 1.16622202e-01, ...,\n",
       "       1.58512584e-06, 1.58512584e-06, 0.00000000e+00])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to the Original weights\n",
    "Thanks to @vkagklis who spotted the issue and @newbielch who showed how to fix it, the difference between original and calculated weights is less than 0.00001"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Predicted weights\n",
    "W_df = pd.DataFrame(W,index = roll_index,columns=['w'])\n",
    "\n",
    "# Load the original weights:\n",
    "data_pass = '/kaggle/input/original-weights/'\n",
    "W_original_df = pd.read_csv(data_pass+'weights_validation.csv')\n",
    "\n",
    "# Set new index, calculate difference between original and predicted:\n",
    "W_original_df = W_original_df.set_index(W_df.index)\n",
    "W_original_df['Predicted'] = W_df.w\n",
    "W_original_df['diff'] = W_original_df.Weight - W_original_df.Predicted\n",
    "\n",
    "# See where we are off by more than e-6\n",
    "m = W_original_df.Weight.values - W_df.w.values > 0.000001\n",
    "W_original_df[m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: As we see our index matches Level_ids and Agg levels of the original dataset, so the **csr_matrix works accurately**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SW dataframe:\n",
    "Pickle dump of S and W weights and roll index for easy loading in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SW = W/np.sqrt(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_df = pd.DataFrame(np.stack((S, W, SW), axis=-1),index = roll_index,columns=['s','w','sw'])\n",
    "sw_df.to_pickle('adata/sw_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sw_df.to_csv('adata/sw_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WRMSSE\n",
    "\n",
    "If you just need to calculate WRMSEE with default weights S, W, simply load them and use the function below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for WRMSSE calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to do quick rollups:\n",
    "def rollup(v):\n",
    "    '''\n",
    "    v - np.array of size (30490 rows, n day columns)\n",
    "    v_rolledup - array of size (n, 42840)\n",
    "    '''\n",
    "    return roll_mat_csr*v #(v.T*roll_mat_csr.T).T\n",
    "\n",
    "\n",
    "# Function to calculate WRMSSE:\n",
    "def wrmsse(preds, y_true, score_only=False, s = S, w = W, sw=SW):\n",
    "    '''\n",
    "    preds - Predictions: pd.DataFrame of size (30490 rows, N day columns)\n",
    "    y_true - True values: pd.DataFrame of size (30490 rows, N day columns)\n",
    "    sequence_length - np.array of size (42840,)\n",
    "    sales_weight - sales weights based on last 28 days: np.array (42840,)\n",
    "    '''\n",
    "    \n",
    "    if score_only:\n",
    "        return np.sum(\n",
    "                np.sqrt(\n",
    "                    np.mean(\n",
    "                        np.square(rollup(preds.values-y_true.values))\n",
    "                            ,axis=1)) * sw)/12 #<-used to be mistake here\n",
    "    else: \n",
    "        score_matrix = (np.square(rollup(preds.values-y_true.values)) * np.square(w)[:, None])/ s[:, None]\n",
    "        score = np.sum(np.sqrt(np.mean(score_matrix,axis=1)))/12 #<-used to be mistake here\n",
    "        return score, score_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wieghts for WRMSSE calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fold pass here:\n",
    "file_pass = 'adata/'# '/kaggle/input/fast-wrmsse-and-sw-frame/'\n",
    "\n",
    "# Load S and W weights for WRMSSE calcualtions:\n",
    "sw_df = pd.read_pickle(file_pass+'sw_df.pkl')\n",
    "S = sw_df.s.values\n",
    "W = sw_df.w.values\n",
    "SW = sw_df.sw.values\n",
    "\n",
    "# Load roll up matrix to calcualte aggreagates:\n",
    "roll_mat_df = pd.read_pickle(file_pass+'roll_mat_df.pkl')\n",
    "roll_index = roll_mat_df.index\n",
    "roll_mat_csr = csr_matrix(roll_mat_df.values)\n",
    "del roll_mat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create fake predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions:\n",
    "sub = pd.read_csv('rawdata/sample_submission.csv')\n",
    "sub = sub[sub.id.str.endswith('validation')]\n",
    "sub.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "DAYS_PRED = sub.shape[1]    # 28\n",
    "\n",
    "# Ground truth:\n",
    "dayCols = [\"d_{}\".format(i) for i in range(1914-DAYS_PRED, 1914)]\n",
    "y_true = sales[dayCols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate score:\n",
    "If you just need the score, set Score_only = True for slightly faster calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.5 ms ± 116 µs per loop (mean ± std. dev. of 5 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "# n - execute the statement n times \n",
    "# r - repeat each loop r times and return the best\n",
    "\n",
    "score = wrmsse(sub, y_true, score_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.4 ms ± 85.1 µs per loop (mean ± std. dev. of 5 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 100 -r 5\n",
    "# n - execute the statement n times \n",
    "# r - repeat each loop r times and return the best\n",
    "\n",
    "score1, score_matrix = wrmsse(sub, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score df for visualizations:\n",
    "score_matrix is only needed for EDA and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.288906059212606"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = wrmsse(sub, y_true, score_only=True)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.288906059212606"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1, score_matrix = wrmsse(sub, y_true)\n",
    "score_df = pd.DataFrame(score_matrix, index = roll_index)\n",
    "score_df.reset_index(inplace=True)\n",
    "score_df.head()\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
